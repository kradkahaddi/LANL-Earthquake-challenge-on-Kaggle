{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LANL_Challenge_LGBM_and_XGB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kradkahaddi/LANL-Earthquake-challenge-on-Kaggle/blob/master/LANL_Challenge_LGBM_and_XGB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRV779iLivzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing google file interface\n",
        "from google.colab import files\n",
        "\n",
        "#creating a variable to store kaggle authenticator .json file\n",
        "uploaded = files.upload()\n",
        "\n",
        "#shifting the kaggle variable to the appropriate folder\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azFQS68ojycR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list the datasets available\n",
        "!kaggle competitions list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0IMmgTSkJtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#WARNING DONT RUN UNNECESSARILY\n",
        "#delete old instance of data\n",
        "!find . -type f -name '*.zip' -delete"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziC96WP2j-wZ",
        "colab_type": "code",
        "outputId": "02759533-9643-4cfe-a713-be12e3c160ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "#download the appropriate dataset - in this case, the LANL-Earthquake-Prediotion dataset\n",
        "!kaggle competitions download -c LANL-Earthquake-Prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sample_submission.csv to /content\n",
            "\r  0% 0.00/33.3k [00:00<?, ?B/s]\n",
            "100% 33.3k/33.3k [00:00<00:00, 28.1MB/s]\n",
            "Downloading test.zip to /content\n",
            " 93% 225M/242M [00:01<00:00, 149MB/s]\n",
            "100% 242M/242M [00:01<00:00, 132MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "100% 2.02G/2.03G [00:35<00:00, 22.1MB/s]\n",
            "100% 2.03G/2.03G [00:36<00:00, 60.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsj-PKzllyDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSIeUQDdk096",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create folders for test data and unzip files\n",
        "!mkdir test\n",
        "!unzip test.zip -d test\n",
        "!unzip train.csv.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-s0TFjYoNeo",
        "colab_type": "text"
      },
      "source": [
        "                        \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "                        **RERUN ONLY AFTER THIS CELL IN CASE OF CRASHES**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RddPZcD3sCX2",
        "colab_type": "code",
        "outputId": "97166cff-6969-475d-c461-86a2f6b78a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#importing libraries and declaring constants\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "from numpy.fft import *\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pywt \n",
        "from statsmodels.robust import mad\n",
        "import scipy\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, deconvolve\n",
        "import scipy.stats \n",
        "import glob\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#IMPORTING THE MODEL\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "SAMPLE_RATE = 4000000\n",
        "SIGNAL_LEN  = 150000      \n",
        "\n",
        "print(\"import and globals setup complete\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import and globals setup complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg7UqgZsJHi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DETECT PEAKS LIBRARY FROM MARCOS DUARTE\n",
        "# https://nbviewer.jupyter.org/github/demotu/BMC/blob/master/notebooks/DetectPeaks.ipynb\n",
        "# %load ./../functions/detect_peaks.py\n",
        "\"\"\"Detect peaks in data based on their amplitude and other features.\"\"\"\n",
        "\n",
        "from __future__ import division, print_function\n",
        "import numpy as np\n",
        "\n",
        "__author__ = \"Marcos Duarte, https://github.com/demotu/BMC\"\n",
        "__version__ = \"1.0.5\"\n",
        "__license__ = \"MIT\"\n",
        "\n",
        "\n",
        "def detect_peaks(x, mph=None, mpd=1, threshold=0, edge='rising',\n",
        "                 kpsh=False, valley=False, show=False, ax=None):\n",
        "\n",
        "    \"\"\"Detect peaks in data based on their amplitude and other features.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : 1D array_like\n",
        "        data.\n",
        "    mph : {None, number}, optional (default = None)\n",
        "        detect peaks that are greater than minimum peak height (if parameter\n",
        "        `valley` is False) or peaks that are smaller than maximum peak height\n",
        "         (if parameter `valley` is True).\n",
        "    mpd : positive integer, optional (default = 1)\n",
        "        detect peaks that are at least separated by minimum peak distance (in\n",
        "        number of data).\n",
        "    threshold : positive number, optional (default = 0)\n",
        "        detect peaks (valleys) that are greater (smaller) than `threshold`\n",
        "        in relation to their immediate neighbors.\n",
        "    edge : {None, 'rising', 'falling', 'both'}, optional (default = 'rising')\n",
        "        for a flat peak, keep only the rising edge ('rising'), only the\n",
        "        falling edge ('falling'), both edges ('both'), or don't detect a\n",
        "        flat peak (None).\n",
        "    kpsh : bool, optional (default = False)\n",
        "        keep peaks with same height even if they are closer than `mpd`.\n",
        "    valley : bool, optional (default = False)\n",
        "        if True (1), detect valleys (local minima) instead of peaks.\n",
        "    show : bool, optional (default = False)\n",
        "        if True (1), plot data in matplotlib figure.\n",
        "    ax : a matplotlib.axes.Axes instance, optional (default = None).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ind : 1D array_like\n",
        "        indeces of the peaks in `x`.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The detection of valleys instead of peaks is performed internally by simply\n",
        "    negating the data: `ind_valleys = detect_peaks(-x)`\n",
        "    \n",
        "    The function can handle NaN's \n",
        "\n",
        "    See this IPython Notebook [1]_.\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] http://nbviewer.ipython.org/github/demotu/BMC/blob/master/notebooks/DetectPeaks.ipynb\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> from detect_peaks import detect_peaks\n",
        "    >>> x = np.random.randn(100)\n",
        "    >>> x[60:81] = np.nan\n",
        "    >>> # detect all peaks and plot data\n",
        "    >>> ind = detect_peaks(x, show=True)\n",
        "    >>> print(ind)\n",
        "\n",
        "    >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
        "    >>> # set minimum peak height = 0 and minimum peak distance = 20\n",
        "    >>> detect_peaks(x, mph=0, mpd=20, show=True)\n",
        "\n",
        "    >>> x = [0, 1, 0, 2, 0, 3, 0, 2, 0, 1, 0]\n",
        "    >>> # set minimum peak distance = 2\n",
        "    >>> detect_peaks(x, mpd=2, show=True)\n",
        "\n",
        "    >>> x = np.sin(2*np.pi*5*np.linspace(0, 1, 200)) + np.random.randn(200)/5\n",
        "    >>> # detection of valleys instead of peaks\n",
        "    >>> detect_peaks(x, mph=-1.2, mpd=20, valley=True, show=True)\n",
        "\n",
        "    >>> x = [0, 1, 1, 0, 1, 1, 0]\n",
        "    >>> # detect both edges\n",
        "    >>> detect_peaks(x, edge='both', show=True)\n",
        "\n",
        "    >>> x = [-2, 1, -2, 2, 1, 1, 3, 0]\n",
        "    >>> # set threshold = 2\n",
        "    >>> detect_peaks(x, threshold = 2, show=True)\n",
        "\n",
        "    Version history\n",
        "    ---------------\n",
        "    '1.0.5':\n",
        "        The sign of `mph` is inverted if parameter `valley` is True\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    x = np.atleast_1d(x).astype('float64')\n",
        "    if x.size < 3:\n",
        "        return np.array([], dtype=int)\n",
        "    if valley:\n",
        "        x = -x\n",
        "        if mph is not None:\n",
        "            mph = -mph\n",
        "    # find indices of all peaks\n",
        "    dx = x[1:] - x[:-1]\n",
        "    # handle NaN's\n",
        "    indnan = np.where(np.isnan(x))[0]\n",
        "    if indnan.size:\n",
        "        x[indnan] = np.inf\n",
        "        dx[np.where(np.isnan(dx))[0]] = np.inf\n",
        "    ine, ire, ife = np.array([[], [], []], dtype=int)\n",
        "    if not edge:\n",
        "        ine = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) > 0))[0]\n",
        "    else:\n",
        "        if edge.lower() in ['rising', 'both']:\n",
        "            ire = np.where((np.hstack((dx, 0)) <= 0) & (np.hstack((0, dx)) > 0))[0]\n",
        "        if edge.lower() in ['falling', 'both']:\n",
        "            ife = np.where((np.hstack((dx, 0)) < 0) & (np.hstack((0, dx)) >= 0))[0]\n",
        "    ind = np.unique(np.hstack((ine, ire, ife)))\n",
        "    # handle NaN's\n",
        "    if ind.size and indnan.size:\n",
        "        # NaN's and values close to NaN's cannot be peaks\n",
        "        ind = ind[np.in1d(ind, np.unique(np.hstack((indnan, indnan-1, indnan+1))), invert=True)]\n",
        "    # first and last values of x cannot be peaks\n",
        "    if ind.size and ind[0] == 0:\n",
        "        ind = ind[1:]\n",
        "    if ind.size and ind[-1] == x.size-1:\n",
        "        ind = ind[:-1]\n",
        "    # remove peaks < minimum peak height\n",
        "    if ind.size and mph is not None:\n",
        "        ind = ind[x[ind] >= mph]\n",
        "    # remove peaks - neighbors < threshold\n",
        "    if ind.size and threshold > 0:\n",
        "        dx = np.min(np.vstack([x[ind]-x[ind-1], x[ind]-x[ind+1]]), axis=0)\n",
        "        ind = np.delete(ind, np.where(dx < threshold)[0])\n",
        "    # detect small peaks closer than minimum peak distance\n",
        "    if ind.size and mpd > 1:\n",
        "        ind = ind[np.argsort(x[ind])][::-1]  # sort ind by peak height\n",
        "        idel = np.zeros(ind.size, dtype=bool)\n",
        "        for i in range(ind.size):\n",
        "            if not idel[i]:\n",
        "                # keep peaks with the same height if kpsh is True\n",
        "                idel = idel | (ind >= ind[i] - mpd) & (ind <= ind[i] + mpd) \\\n",
        "                    & (x[ind[i]] > x[ind] if kpsh else True)\n",
        "                idel[i] = 0  # Keep current peak\n",
        "        # remove the small peaks and sort back the indices by their occurrence\n",
        "        ind = np.sort(ind[~idel])\n",
        "\n",
        "    if show:\n",
        "        if indnan.size:\n",
        "            x[indnan] = np.nan\n",
        "        if valley:\n",
        "            x = -x\n",
        "            if mph is not None:\n",
        "                mph = -mph\n",
        "        _plot(x, mph, mpd, threshold, edge, valley, ax, ind)\n",
        "\n",
        "    return ind\n",
        "\n",
        "\n",
        "def _plot(x, mph, mpd, threshold, edge, valley, ax, ind):\n",
        "    \"\"\"Plot results of the detect_peaks function, see its help.\"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "    except ImportError:\n",
        "        print('matplotlib is not available.')\n",
        "    else:\n",
        "        if ax is None:\n",
        "            _, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
        "\n",
        "        ax.plot(x, 'b', lw=1)\n",
        "        if ind.size:\n",
        "            label = 'valley' if valley else 'peak'\n",
        "            label = label + 's' if ind.size > 1 else label\n",
        "            ax.plot(ind, x[ind], '+', mfc=None, mec='r', mew=2, ms=8,\n",
        "                    label='%d %s' % (ind.size, label))\n",
        "            ax.legend(loc='best', framealpha=.5, numpoints=1)\n",
        "        ax.set_xlim(-.02*x.size, x.size*1.02-1)\n",
        "        ymin, ymax = x[np.isfinite(x)].min(), x[np.isfinite(x)].max()\n",
        "        yrange = ymax - ymin if ymax > ymin else 1\n",
        "        ax.set_ylim(ymin - 0.1*yrange, ymax + 0.1*yrange)\n",
        "        ax.set_xlabel('Data #', fontsize=14)\n",
        "        ax.set_ylabel('Amplitude', fontsize=14)\n",
        "        mode = 'Valley detection' if valley else 'Peak detection'\n",
        "        ax.set_title(\"%s (mph=%s, mpd=%d, threshold=%s, edge='%s')\"\n",
        "                     % (mode, str(mph), mpd, str(threshold), edge))\n",
        "        # plt.grid()\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUOrwoKonS8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "I am really grateful the work put into this public kernel that explains denoising:\n",
        "\n",
        "https://www.kaggle.com/tarunpaparaju/lanl-earthquake-prediction-signal-denoising\n",
        "\n",
        "The functions are borrowed directly from there. \n",
        "\"\"\"\n",
        "\n",
        "def maddest(d, axis=None):\n",
        "    \"\"\"\n",
        "    Mean Absolute Deviation\n",
        "    \"\"\"\n",
        "    \n",
        "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
        "  \n",
        "  \n",
        "def high_pass_filter(x, low_cutoff=1000, SAMPLE_RATE=SAMPLE_RATE):\n",
        "    \"\"\"\n",
        "    From @randxie https://github.com/randxie/Kaggle-VSB-Baseline/blob/master/src/utils/util_signal.py\n",
        "    Modified to work with scipy version 1.1.0 which does not have the fs parameter\n",
        "    \"\"\"\n",
        "    \n",
        "    # nyquist frequency is half the sample rate https://en.wikipedia.org/wiki/Nyquist_frequency\n",
        "    nyquist = 0.5 * SAMPLE_RATE\n",
        "    norm_low_cutoff = low_cutoff / nyquist\n",
        "    \n",
        "    # Fault pattern usually exists in high frequency band. According to literature, the pattern is visible above 10^4 Hz.\n",
        "    sos = butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n",
        "    filtered_sig = signal.sosfilt(sos, x)\n",
        "\n",
        "    return filtered_sig\n",
        "\n",
        "\n",
        "def denoise_signal(x, wavelet='db4', level=1):\n",
        "    \"\"\"\n",
        "    1. Adapted from waveletSmooth function found here:\n",
        "    http://connor-johnson.com/2016/01/24/using-pywavelets-to-remove-high-frequency-noise/\n",
        "    2. Threshold equation and using hard mode in threshold as mentioned\n",
        "    in section '3.2 denoising based on optimized singular values' from paper by Tomas Vantuch:\n",
        "    http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
        "    \"\"\"\n",
        "    \n",
        "    # Decompose to get the wavelet coefficients\n",
        "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
        "    \n",
        "    # Calculate sigma for threshold as defined in http://dspace.vsb.cz/bitstream/handle/10084/133114/VAN431_FEI_P1807_1801V001_2018.pdf\n",
        "    # As noted by @harshit92 MAD referred to in the paper is Mean Absolute Deviation not Median Absolute Deviation\n",
        "    sigma = (1/0.6745) * maddest(coeff[-level])\n",
        "\n",
        "    # Calculate the univeral threshold\n",
        "    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
        "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
        "    \n",
        "    # Reconstruct the signal using the thresholded coefficients\n",
        "    return pywt.waverec(coeff, wavelet, mode='per')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUNpwvQY3Wfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finds the max rate change of order of difference between peaks and the surrounds - similar to an tangent\n",
        "\n",
        "def left_side_diff_max(X, mph = 0, mpd =0):\n",
        "  indices = []\n",
        "  indices = detect_peaks(X, mph = mpd, mpd = mpd)\n",
        "  diff = list()\n",
        "  \n",
        "  surrounding_range = mpd//2\n",
        "  \n",
        "  for index in indices:\n",
        "    range_fn = index - surrounding_range -1\n",
        "    if (range_fn >=0):\n",
        "      diff.append((X[index] - X[range_fn: index -1].mean())/surrounding_range)\n",
        "    else:\n",
        "      diff.append((X[index] - X[0:index -1].mean())/(index-1))\n",
        "    \n",
        "  diff_pd = pd.Series(diff)\n",
        "  \n",
        "  return diff_pd.max()\n",
        "   \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVdcC3Cf7NQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finds the avg rate change of order of difference between peaks and the surrounds - similar to an tangent\n",
        "\n",
        "def left_side_diff_mean(X, mph = 0, mpd =0):\n",
        "  indices = []\n",
        "  indices = detect_peaks(X, mph = mph, mpd = mpd)\n",
        "  diff = list()\n",
        "  \n",
        "  surrounding_range = mpd//2\n",
        "  \n",
        "  for index in indices:\n",
        "    range_fn = index - surrounding_range -1\n",
        "    if (range_fn >=0):\n",
        "      diff.append((X[index] - X[range_fn: index -1].mean())/surrounding_range)\n",
        "    else:\n",
        "      diff.append((X[index] - X[0:index -1].mean())/(index-1))\n",
        "  \n",
        "  diff_pd = pd.Series(diff)\n",
        "  \n",
        "  return diff_pd.mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAXwnlC673wD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finds the max rate change of order of difference between peaks and the surrounds - similar to an tangent\n",
        "\n",
        "def right_side_diff_max(X, mph = 0, mpd =0):\n",
        "  indices = []\n",
        "  indices = detect_peaks(X, mph = mph, mpd = mpd)\n",
        "  diff = list()\n",
        "  \n",
        "  surrounding_range = mpd//2\n",
        "  \n",
        "  for index in indices:\n",
        "    range_fn = index + surrounding_range + 1\n",
        "    if (range_fn <=len(X)):\n",
        "      diff.append((X[index] - X[index+1: range_fn].mean())/surrounding_range)\n",
        "    else:\n",
        "      diff.append((X[index] - X[index+1: len(X)].mean())/(len(X) - index - 1))\n",
        "    \n",
        "  diff_pd = pd.Series(diff)\n",
        "  \n",
        "  return diff_pd.max()\n",
        "   \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grpG-HDy9hXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Finds the max rate change of order of difference between peaks and the surrounds - similar to an tangent\n",
        "\n",
        "def right_side_diff_mean(X, mph = 0, mpd =0):\n",
        "  indices = []\n",
        "  indices = detect_peaks(X, mph = mph, mpd = mpd)\n",
        "  diff = list()\n",
        "  \n",
        "  surrounding_range = mpd//2\n",
        "  \n",
        "  for index in indices:\n",
        "    range_fn = index + surrounding_range + 1\n",
        "    if (range_fn <=len(X)):\n",
        "      diff.append((X[index] - X[index+1: range_fn].mean())/surrounding_range)\n",
        "    else:\n",
        "      diff.append((X[index] - X[index+1: len(X)].mean())/(len(X) - index - 1))\n",
        "  \n",
        "  diff_pd = pd.Series(diff)\n",
        "  \n",
        "  return np.mean(diff_pd)\n",
        "   \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt5dbp3eKMuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def num_groups_data (X, mph =0):\n",
        "  \n",
        "  val = list(np.abs(X))\n",
        "  count = 1\n",
        "  \n",
        "#   indices = list()\n",
        "#   indices_sorted = list()\n",
        "  \n",
        "  indices = np.array(detect_peaks(val,mph = mph))\n",
        "#   indices_sorted.append(list(indices).sort()) #redundant but for the sake of comprehensiveness... c'est la vie!\n",
        "  \n",
        "  maxi = 501\n",
        "  for iterate in range(len(indices) -1):\n",
        "    diff = indices[iterate +1] - indices[iterate]\n",
        "    \n",
        "    if ( maxi <diff):\n",
        "      maxi = diff\n",
        "    \n",
        "  if (maxi > 2000):\n",
        "    maxi=2000 #500 is too little or diff was > 1000\n",
        "  \n",
        "  for iterate in range(len(indices)- 1):\n",
        "    diff = indices[iterate +1] - indices[iterate]\n",
        "    if (diff>maxi):\n",
        "      count +=1\n",
        "  \n",
        "  return count\n",
        "  \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVjCyfXrJ0H2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spread_of_data (X, mph=0):\n",
        "  X_list = list(np.abs(X))\n",
        "  \n",
        "  \n",
        "  indices = np.array(detect_peaks(X_list,mph = mph))\n",
        "#   indices_sorted.append(list(indices).sort()) #redundant but for the sake of comprehensiveness... c'est la vie!\n",
        "\n",
        "  if len(indices) > 0:\n",
        "    return indices[len(indices) - 1] - indices[0] \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fORpjFsr4S4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eg = pd.Series([1,2,3,4,5,6,7])\n",
        "eg[7-3:6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blHFUcdPJVAY",
        "colab_type": "text"
      },
      "source": [
        "                           \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "                           **VISUAL DATA ANALYSIS**\n",
        "                           \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ3JSRR6xrQK",
        "colab_type": "code",
        "outputId": "947f3ae5-4a19-408e-a5df-9a6518cbde52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "188"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK2HNRElhLD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test: print plots in a loop\n",
        "%%time\n",
        "\n",
        "iteration = 0\n",
        "\n",
        "train = pd.read_csv('train.csv', iterator=True, chunksize=150_000, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
        "\n",
        "for df in train:\n",
        "    iteration +=1\n",
        "    \n",
        "    for i in range(20):\n",
        "      continue\n",
        "    \n",
        "    denoised_acoustic_data = high_pass_filter(denoise_signal(df.acoustic_data, wavelet='haar', level=1), low_cutoff = 10000, SAMPLE_RATE = 4000000)\n",
        "    acoustic_data = list(df.acoustic_data)\n",
        "    time_to_failure = list(df.time_to_failure)\n",
        "    \n",
        "    fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(16,8))\n",
        "    \n",
        "    ax1.plot(acoustic_data, 'crimson')\n",
        "    ax1.set_title(\"original acoustic data\", fontsize = 16)\n",
        "    \n",
        "    ax2.plot(denoised_acoustic_data, 'mediumvioletred')\n",
        "    ax2.set_title(\"denoised data\", fontsize = 16)\n",
        "    \n",
        "    ax3 = ax1.twinx()\n",
        "    ax3.plot(time_to_failure, 'darkmagenta')\n",
        "    ax3.set_title(\"time to failure\", fontsize = 16)\n",
        "    \n",
        "    ax4 = ax2.twinx()\n",
        "    ax4.plot(time_to_failure, 'darkmagenta')\n",
        "    ax4.set_title(\"time to failure\", fontsize = 16)\n",
        "    \n",
        "    x = input(\"Continue? y/n \")\n",
        "    if(x=='n'):\n",
        "      print(\"iteration is \", iteration)\n",
        "      break\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD4g2c9BaC7k",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**PREDICTION OF EARTHQUAKES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-ZjJon3zkE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generating features\n",
        "def gen_features(X):\n",
        "    strain = []\n",
        "    strain.append(X.mean())\n",
        "    strain.append(X.std())\n",
        "    strain.append(X.min())\n",
        "    strain.append(X.max())\n",
        "    strain.append(scipy.stats.kurtosis(X))\n",
        "    strain.append(scipy.stats.skew(X))\n",
        "    strain.append(np.quantile(X,0.01))\n",
        "    strain.append(np.quantile(X,0.05))\n",
        "    strain.append(np.quantile(X,0.95))\n",
        "    strain.append(np.quantile(X,0.99))\n",
        "    strain.append(np.abs(X).max())\n",
        "    strain.append(np.abs(X).mean())\n",
        "    strain.append(np.abs(X).std())\n",
        "    \n",
        "    \n",
        "#     strain.append(len(detect_peaks(X, mph=20))) - discard\n",
        "#     strain.append(len(detect_peaks(X, mph=50)))\n",
        "#     strain.append(len(detect_peaks(X, mph=100)))\n",
        "    \n",
        "    #measure of sustained activity\n",
        "    strain.append(len(detect_peaks(np.abs(X), mph=20, mpd=3000))) \n",
        "    strain.append(len(detect_peaks(np.abs(X), mph=50, mpd=1000)))\n",
        "    strain.append(len(detect_peaks(np.abs(X), mph=100, mpd=20)))\n",
        "    \n",
        "    #measuring rate of change    - keep\n",
        "    strain.append(right_side_diff_mean(X, mph=50, mpd =500))\n",
        "    strain.append(right_side_diff_max(X, mph=50, mpd =500))\n",
        "    strain.append(left_side_diff_mean(X, mph=50, mpd =500))\n",
        "    strain.append(left_side_diff_max(X, mph=50, mpd =500))\n",
        "    \n",
        "#     strain.append(spread_of_data (X, mph =50)) -discard\n",
        "    strain.append(spread_of_data (X, mph =100))\n",
        "\n",
        "#measuring rate of change around tall peaks - discard\n",
        "#     strain.append(right_side_diff_mean(X, mph=100, mpd =50))\n",
        "#     strain.append(right_side_diff_max(X, mph=100, mpd =1000))\n",
        "#     strain.append(left_side_diff_mean(X, mph=100, mpd =50))\n",
        "#     strain.append(left_side_diff_max(X, mph=100, mpd =1000))\n",
        "\n",
        "    #measuring grouping of data\n",
        "    strain.append(num_groups_data(X, mph =50))\n",
        "    strain.append(num_groups_data(X, mph =100))\n",
        "    \n",
        "    \n",
        "    return pd.Series(strain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQKa6tpDN_tw",
        "colab_type": "code",
        "outputId": "fb1ce5a9-1334-47ed-f9a5-47ba2eb950f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Arj86_2YSAZ0",
        "colab_type": "code",
        "outputId": "88173b05-98cc-4f75-8141-612769369b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "train = pd.read_csv('train.csv', iterator=True, chunksize=150_000, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.21 ms, sys: 3.62 ms, total: 5.83 ms\n",
            "Wall time: 10.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vKtSJiwpurN",
        "colab_type": "code",
        "outputId": "bd18e650-93c1-4184-e1cf-02b5b72c534b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "iterate = 0\n",
        "X_train = pd.DataFrame()\n",
        "y_train = pd.Series()\n",
        "X_valid = pd.DataFrame()\n",
        "y_valid = pd.Series()\n",
        "\n",
        "\n",
        "train = pd.read_csv('train.csv', iterator=True, chunksize=150_000, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
        "\n",
        "for df in train:\n",
        "    denoised_acoustic_data = high_pass_filter(denoise_signal(df.acoustic_data, wavelet='haar', level=1), low_cutoff = 10000, SAMPLE_RATE = 4000000) \n",
        "    ch = gen_features(denoised_acoustic_data)\n",
        "#     ch = gen_features(df.acoustic_data)\n",
        "    \n",
        "    if (iterate < 3500):\n",
        "      X_train = X_train.append(ch, ignore_index=True)\n",
        "      y_train = y_train.append(pd.Series(df['time_to_failure'].values[-1]))\n",
        "    else:\n",
        "      X_valid = X_valid.append(ch, ignore_index=True)\n",
        "      y_valid = y_valid.append(pd.Series(df['time_to_failure'].values[-1]))\n",
        "    \n",
        "    iterate +=1\n",
        "    \n",
        "X_train = X_train.fillna(0.0)\n",
        "X_valid = X_valid.fillna(0.0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10min 54s, sys: 49.7 s, total: 11min 44s\n",
            "Wall time: 11min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh624qCem6JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.fillna(0.0)\n",
        "X_valid = X_valid.fillna(0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghc8WtGo1lL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSpLrmO7R6nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_valid.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfmW2SSs5g8Z",
        "colab_type": "code",
        "outputId": "2be66648-664b-44a8-acf5-0700edbe5355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "#XGB hyperparameter sets are (n=4k, rate=0.025) and (n=10k, rate=0.01)\n",
        "my_model = XGBRegressor(n_estimators=1000, learning_rate = 0.01, random_state=0)\n",
        "\n",
        "my_model.fit(X_train,y_train,eval_metric='mae')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17:16:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n",
              "             max_depth=3, min_child_weight=1, missing=None, n_estimators=1000,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0yOGvTBAXML",
        "colab_type": "code",
        "outputId": "a71d1eb6-59c2-474a-8c75-bdbcac05b951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#WITHOUT TEST VALID SPLIT\n",
        "\n",
        "#Hyper parameters  (2000, 0.025) = 1.5558\n",
        "#                  (1500, 0.05)  = 1.3577\n",
        "#                  (2000, 0.05)  = 1.2070\n",
        "#                  (3000, 0.025) = 1.3712\n",
        "#                  (3000, 0.05)  = 0.9592\n",
        "#                  (3500, 0.025) = 1.2864\n",
        "#                  (4000, 0.025) = 1.2130\n",
        "#                 (10000, 0.001) = 1.9647\n",
        "#                 (10000, 0.01)  = 1.2085\n",
        "#                 (20000, 0.001) = 1.8432\n",
        "#                 (20000, 0.01)  = 0.7864\n",
        "#                 (20000, 0.005) = 1.2162\n",
        "# choosing (10000, 0.01) and (4000, 0.025) as hyperparameters\n",
        "\n",
        "# without basic peak info - 1.8804\n",
        "# without basic peak info and abs stats - 1.8824\n",
        "# with abs stats removed - 1.8799\n",
        "\n",
        "# with 3600 train-set and basic peak removed - 1.9236\n",
        "# with (10000, 0.01) and b.p. removed - 1.1243\n",
        "# with (5000, 0.01) and b.p. removed - 1.4870\n",
        "# with (500, 0.01) and b.p. removed - 1.9994\n",
        "\n",
        "\n",
        "# with (500, 0.05) and b.p. removed - 1.7232 - overfit\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "predictions = my_model.predict(X_train)\n",
        "\n",
        "MAE = mean_absolute_error(predictions,y_train)\n",
        "print(MAE)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8412690642361813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ub65ep2P0el",
        "colab_type": "code",
        "outputId": "8a2b1e46-2b65-40aa-9989-e796436c9e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#WITH TEST VALID SPLIT\n",
        "#with basic peak count - 2.3011\n",
        "#with basic peak count removed - 2.2908\n",
        "#with basic peak count and abs stats removed -2.2929\n",
        "#with abs stats removed - 2.3008\n",
        "#with 3600 train-set and basic peak removed - 2.1932\n",
        "# with (10000, 0.01) and b.p. removed - 2.3186\n",
        "# with (5000, 0.01) and b.p. removed - 2.2508\n",
        "# with (500, 0.01) and b.p. removed - 2.1887\n",
        "\n",
        "\n",
        "\n",
        "# with (500, 0.05) and b.p. removed - 2.2362 -overfit\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "val_predictions = my_model.predict(X_valid)\n",
        "\n",
        "val_MAE = mean_absolute_error(val_predictions,y_valid)\n",
        "print(val_MAE)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5443048792521563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G8Km3UbAHah",
        "colab_type": "code",
        "outputId": "ae988426-ebba-4707-b638-ea5f70b2014c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%%time\n",
        "X_test = pd.DataFrame()\n",
        "\n",
        "for file_name in glob.glob('test/*.csv'):\n",
        "    \n",
        "  data = pd.read_csv(file_name)\n",
        "  denoised_data = high_pass_filter(denoise_signal(data.acoustic_data, wavelet='haar', level=1), low_cutoff = 10000, SAMPLE_RATE = 4000000)\n",
        "  \n",
        "  ft = gen_features(denoised_data)\n",
        "  X_test = X_test.append(ft, ignore_index=True)\n",
        "  X_test = X_test.fillna(0.0)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 38s, sys: 16.6 s, total: 5min 54s\n",
            "Wall time: 6min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-REidqJ8aUMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATING AN OUTPUT VARIABLE\n",
        "test_predictions = pd.DataFrame({'seg_id':[],'time_to_failure':[]})\n",
        "# test_predictions.columns = ['seg_id','time_to_failure']\n",
        "test_predictions.columns\n",
        "\n",
        "for file_name in os.listdir('test/'):\n",
        "  seg_name = file_name\n",
        "  name_seg = seg_name.replace('.csv','')\n",
        "\n",
        "  test_predictions = test_predictions.append({'seg_id':name_seg}, ignore_index= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W15b30oBbhEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrS1QWL8dLqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52r3b5kOisE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_predictions = my_model.predict(X_test)\n",
        "test_predictions.time_to_failure = my_predictions\n",
        "test_predictions.to_csv('output8_XGB.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPnfrRsxSp2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSH8WxO4IpbH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "                                               ***LIGHT-GBM ALGORITHM ATTEMPT***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpL43MjNIowU",
        "colab_type": "code",
        "outputId": "d4b06f95-6bbd-4dcd-be97-792079d83f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "my_lgbm_model = LGBMRegressor(max_depth = -1, n_estimators =400, learning_rate =0.01, random_state =0)\n",
        "my_lgbm_model.fit(X_train, y_train, eval_metric ='mae')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "              importance_type='split', learning_rate=0.01, max_depth=-1,\n",
              "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "              n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,\n",
              "              random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFFh1inIKwoR",
        "colab_type": "code",
        "outputId": "918624cf-8b93-4d52-b580-1353040cc64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#LGBM Model hyper parameter tuning\n",
        "#                  (2000, 0.025) = \n",
        "#                  (1500, 0.05)  = \n",
        "#                  (2000, 0.05)  = \n",
        "#                  (3000, 0.025) = \n",
        "#                  (3000, 0.05)  = \n",
        "#                  (3500, 0.025) = \n",
        "#                  (4000, 0.025) = \n",
        "#                 (10000, 0.001) = 1.5212 \n",
        "#                 (10000, 0.01)  = 0.2646\n",
        "#                 (10000, 0.005) = 0.6516\n",
        "#                 (20000, 0.001) = \n",
        "#                 (20000, 0.01)  = \n",
        "#                 (20000, 0.005) = \n",
        "\n",
        "# with abs stats and basic peak count removed - 1.3851\n",
        "# with abs stats removed - 1.3697\n",
        "# with 3600 train-set and basic peak removed - 1.4387\n",
        "# with (10000, 0.01) and b.p. removed - 0.2399\n",
        "# with (5000, 0.01) and b.p. removed - 0.5780\n",
        "# with (500, 0.01) and b.p. removed - 1.6743\n",
        "# with (400, 0.01) and b.p. removed - 1.7414\n",
        "# with (100, 0.01) and b.p. removed - 2.1678 -underfit\n",
        "\n",
        "# with (300, 0.01) and b.p. removed - 1.8233\n",
        "# with (250, 0.01) and b.p. removed - 1.8741\n",
        "\n",
        "# with (500, 0.05) and b.p. removed - 0.9801 -overfit\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "predictions_lgbm = my_lgbm_model.predict(X_train)\n",
        "\n",
        "MAE_lgbm = mean_absolute_error(predictions_lgbm,y_train)\n",
        "print(MAE_lgbm)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8536927301967585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0WExTZvQZYL",
        "colab_type": "code",
        "outputId": "548024d7-aff6-43de-9832-b4cd7e2e0ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#LGBM VALIDATION\n",
        "#WITH TEST VALID SPLIT\n",
        "# with basic peak count - 2.3351\n",
        "# with basic peak count removed - 2.316\n",
        "# with basic peak count and abs stats removed - 2.3163\n",
        "# with abs stats removed - 2.3261\n",
        "# with 3600 train-set and basic peak removed - 2.2400\n",
        "# with (10000, 0.01) and b.p. removed - 2.3665\n",
        "# with (5000, 0.01) and b.p. removed - 2.3340\n",
        "# with (500, 0.01) and b.p. removed - 2.2053\n",
        "# with (400, 0.01) and b.p. removed - 2.1895\n",
        "# with (100, 0.01) and b.p. removed - 2.2007 - underfit\n",
        "\n",
        "# with (300, 0.01) and b.p. removed - 2.1769\n",
        "# with (250, 0.01) and b.p. removed - 2.1615\n",
        "\n",
        "# with (500, 0.05) and b.p. removed - 2.3007 - overfit\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "val_predictions_lgbm = my_lgbm_model.predict(X_valid)\n",
        "\n",
        "val_MAE_lgbm = mean_absolute_error(val_predictions_lgbm,y_valid)\n",
        "print(val_MAE_lgbm)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5658551834032295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMV3yP3akKPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exKx56jVOBdB",
        "colab": {}
      },
      "source": [
        "#CREATING AN OUTPUT VARIABLE\n",
        "lgbm_test_predictions = pd.DataFrame({'seg_id':[],'time_to_failure':[]})\n",
        "# test_predictions.columns = ['seg_id','time_to_failure']\n",
        "lgbm_test_predictions.columns\n",
        "\n",
        "for file_name in os.listdir('test/'):\n",
        "  seg_name = file_name\n",
        "  name_seg = seg_name.replace('.csv','')\n",
        "\n",
        "  lgbm_test_predictions = lgbm_test_predictions.append({'seg_id':name_seg}, ignore_index= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sD1zCkwwOBdQ",
        "colab": {}
      },
      "source": [
        "X_test.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bFkxlpvmOBdh",
        "colab": {}
      },
      "source": [
        "lgbm_test_predictions.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9GDCy1yvOBdq",
        "colab": {}
      },
      "source": [
        "my_lgbm_predictions = my_lgbm_model.predict(X_test)\n",
        "lgbm_test_predictions.time_to_failure = my_lgbm_predictions\n",
        "lgbm_test_predictions.to_csv('LGBM_output11.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_51fmKXU5HJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgbm_test_predictions.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDwHYmetjuli",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**CATBOOST ALGOL TRY**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dasJPCjk8mqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkhIPXAz8EG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CatBoost Model\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "\n",
        "train_pool = Pool(X_train, y_train)\n",
        "m = CatBoostRegressor(iterations=10000, loss_function='MAE', boosting_type='Ordered')\n",
        "m.fit(X_train, y_train, silent=True)\n",
        "m.best_score_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u5-oxmL5XVI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**RESIDUAL CODE AFTER THIS POINT**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y7qLfm8tjUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "denoised_acoustic_data = high_pass_filter(denoise_signal(signals, wavelet='haar', level=1), low_cutoff = 10000, SAMPLE_RATE = 4000000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0ubKq5Dxlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqszdUUzLIhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_names[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th_xINvVCMey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "i = 0\n",
        "for f in glob.glob('test/*csv'):\n",
        "  print(f)\n",
        "  break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqEB657ILlYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob \n",
        "\n",
        "file_names = [f for f in glob.glob('test/*.csv')]\n",
        "len(file_names)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uku-sTOmLTsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_output = pd.read_csv('sample_submission.csv','r')\n",
        "sample_output.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duEwfzqZfZ-v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file_name in glob.glob('test/*.csv'):\n",
        "  seg_name = file_name\n",
        "  name_seg = seg_name.replace('.csv','')\n",
        "\n",
        "  test_predictions = test_predictions.append({'seg_id':name_seg}, ignore_index= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiNvu_3oifWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seg_name = file_name\n",
        "  name_seg = seg_name.replace('.csv','')\n",
        "  nameseg = name_seg.replace('test/','')\n",
        "\n",
        "  test_predictions = test_predictions.append({'seg_id':nameseg}, ignore_index= True)  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}